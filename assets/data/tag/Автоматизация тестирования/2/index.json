{"hash":"84ff211b7c6d9fc18dc1380cbe0fca5225ead0ae","data":{"tag":{"title":"Автоматизация тестирования","path":"/tag/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F/","belongsTo":{"totalCount":21,"pageInfo":{"totalPages":3,"currentPage":2},"edges":[{"node":{"id":"69e2a0e8f352a43863174d1d7360b43a","title":"Что такое Selenium?","content":"\n## Что такое Selenium?\n**Selenium** - это инструмент для автоматизированного управления браузерами _или_ драйвер для браузера, специальное ПО которое предназначено для управления браузерами и позволяет другим программам взаимодействовать с браузером.\n\nSelenium специальных средств для тестирования не имеет, он позволяет только управлять браузером.\n\n## Что умеет Selenium\nОбычно драйвер предоставляет некоторый набор команд, который соответствует некоторым функциям устройства, в нашем случае функциям браузера.\n\nДрайвер может:\n- запускать браузер \n- открывать URL адреса\n- находить ссылки или другие элементы\n- выполнять действия над элементами\n- остановить браузер\n\n## Реализации Selenium\nДля разных браузеров существуют разные драйверы, но они предоставляют одинаковый набор команд.\nТак же существуют разные реализации интерфейсов для разных языков программирования.\n\nВ рамках проекта Selenium разрабатываются интерфейсы для 5 языков:\n- Java\n- Python\n- Ruby\n- JavaScript\n- C#\n\n## Принцип работы\n\nКаждое веб приложение условно можно разделить на 2 части: \n- веб сервер, на котором реализуется логика и находится БД \n- браузер, который предоставляет графический пользовательский интерфейс к этому приложению. \n\nБраузер и веб сервер взаимодействуют по протоколу HTTP. Браузер отправляет запрос, сервер его обрабатывает и отправляет обратно ответ.\nЭтот ответ содержит информацию, которую браузер использует для визуализации. \n\nДля того, чтобы тестировать серверную часть, браузер не нужен, его можно заменить http клиентом(библиотека которая умеет отправлять запросы по протоколу http и получать ответы), такие клиенты сузествуют для разных языков они не имеют пользовательского интерфейс, только программный(API). \n\nОднако такой способ игнорирует всё, что происходит в браузере (в браузере может быть реализована часть логики плюс сам интерфес становится более динамичным и его тоже нужно тестировать).\n\nSelenium предоставляет клиентскую библиотеку для разных языков программирования, через которую можно связаться с самим Selenium интерфейсом, который уже взаимодействует с браузером.\n\nБольшинство браузеров сейчас  предоставляют интерфейс для управления или отладки, которым можно воспользоваться для внедрения JavaScript кода и выполнения этого кода в браузере.\n\nИзначально браузеры не предоставляли такие интерфейсы, кроме IExplorer и в нем работа была реализована изначально таким способом. Но потом появилась возможность взаимодействовать через интерфейсы и с другими браузерами.\n\n### Интерфесы которые предоставляют браузеры\nРазные браузеры предоставляют разные интерфейсы:\n- Chrome - Remote Debug\n- Firefox - Marionette\n- IE - COM API\n\n### Selenium интерфейсы для разных браузеров\nSelenium предоставляет единый интерфейс, а сам взаимодействует с браузерами по их интерфейсу:\n- Chrome - chromedriver\n- Firefox - geckodriver\n- IE - IEDriverServer","date":"2022-06-12T00:00:00.000Z","path":"/chto-takoe-selenium/","icon":"fas fa-robot","image":"null","order":null,"category":{"title":"automation","path":"/category/automation/"},"tags":[{"title":"Автоматизация тестирования","path":"/tag/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F/"}],"headings":[{"value":"Что такое Selenium?","anchor":"#что-такое-selenium"},{"value":"Что умеет Selenium","anchor":"#что-умеет-selenium"},{"value":"Реализации Selenium","anchor":"#реализации-selenium"},{"value":"Принцип работы","anchor":"#принцип-работы"}]}},{"node":{"id":"703c641b88145adc725ea1a1585a102d","title":"Gradle","content":"\nGradle - это инструмент для автоматической сборки приложений. Он отвечает за структуру, зависимости, плагины вашего проекта, чтобы управлять этапами сборки проекта: компиляция, запуск тестов, публикация. \n\nGradle написан на Java и запускается на JVM, поэтому нужно чтобы был установлен JDK. При этом Gradle не заточен только под java приложения и может собирать любые другие. \n\nДля реализации и описания процесса сборки в Gradle реализовано 2 DSL языка на Groovy и на Kotlin.\nОба этих языка предоставляют примерно одинаковый API для работы со сборкой и имеют 2 интерфейса, которые эту сборку описывают.\n\n`project` - описывает как и из чего собрать проект;  \n`settings.gradle` - описывает дополнительные метаданные и список дочерних проектов, если это мультимодульный проект;\n\n## `project`\n\n### task\nПредставляет собой набор задач, который вам нужно выполнить для сборки приложения; эти задачи можно писать самим или добавлять через плагины.\n\n### plugin\nБольшинство функционала gradle реализуется с помощью плагинов, поэтому сам gradle изначально достаточно легкий и не содержит лишнего мусора.\n\nПлагин - это реализация методов интерфейса проекта(project), которые могут реализовывать работу с зависимостями, добавлять нужные таски и почти полностью менять, то как работает процесс сборки.\n\n### dependencies\nМожно указать необходимые зависимости для работы вашего приложения. Gradle реализует только логику управления зависимостями а сам репозиторий можно выбрать, настроив это в build скрипте. Это может быть например maven или ivy репозиторий.\n\nТип Task в Gradle это по сути класс. Он состоит из действий(actions), которые выполняет класс, входных данных(inputs), над которыми мы производим действия и выходных данных(outputs). \n\nКаждая из этих состовляющих кастомизируема и необязательна. Например, существуют LifeCycle таски, которые сами ничего не делают, но объединяют несколько других тасок.\n\nЗа счет такого разделения Gradle реализует **_инкрементальную_** сборку: перед выполнением таски Gradle проверяет есть ли изменения входных данных и повлияют ли эти изменеия на выходные данные. Если нет, то Gradle просто пропустит таск с надписью **UP TO DATE**, таким образом оптимизируется процесс сборки, чтобы каждый раз не собирать неизменяемые модули, а собирать только то, что изменилось, но эту логику также можно отключить.\n\nЧтобы обеспечить нужный порядок выполнения тасок и что каждая таска выполнится только один раз, в процессе билдинга Gradle строит из тасок так называемый ориентированный ациклический граф(**DAG, Directed Acyclic Graph**). \n\nГраф - это набор объектов(в нашем случае тасок), обладающих парными связями (каждая таска связана с одной или несколькими(двумя) другими тасками). \n\nТаски - вершины, связи между ними - ребра. \n\nТо что граф ориентированный или по другому орграф значит, что у ребер есть направление (порядок исполнения тасок), то что он ациклический означает, что в нем нет направленных циклов, нельзя из одной точки прийти в нее же, но это не мешает из разных точек прийти в одну. Такие графы много где использются, например для представления искусственных нейронных сетей без обратной связи. \n\n**Граф для сборки Java приложения**\n\n```mermaid\ngraph TD;\n      build-->check;\n      build-->assemble;\n      check-->test;\n      assemble-->jar;\n      jar-->classes;\n      classes-->compileJava;\n      classes-->processResources;\n```\n\n## Сборка Java приложения\nПроцесс сборки делится на 3 тапа: инициализация (initialization), конфигурация (configuration) и исполнение (execution). \n\n### Инициализация\nВ процессе инициализации Gradle ищет `settings.gradle` файл, из которого определяет это одиночный или мультимодульный проект. После этого он создает instance одного или нескольких проектов. \n\n```mermaid\ngraph TD;\n      Initialization-->settings.gradle-->project;\n```\n\n### Конфигурация\nДалее в процессе конфигурации, gradle для каждого проекта ищет build.gradle скрипт и выполняет все указанные там конфигурационные действия в контексте текущего проекта: подключает плагины, скачивает зависимости, выполняет код находящийся в конфигурационном блоке, создавая объекты сборки - строит граф из тасок.\n\n```mermaid\ngraph TD;\n      Configuration-->build.gradle-->build_objects;\n```\n\n\nВо время фазы конфигурации gradle исполняет конфигурационные скрипты всех проектов если это мультимодульный проект, даже если вы собираете только один из модулей. Так что если логика не относится ко всему мультимодульному проекту, лучше ее помещать в конкретные таски. \n\n### Исполнение\n\nПо сути в процессе конфигурации он строит тот самый граф из тасок и в процессе выполнения, исполняет те таски, которые мы указали.\n\n```mermaid\ngraph TD;\n      Execution-->execute_tasks;\n```\n\nИннициализация Gradle проекта выполняется командой gradle init.\n\n```\n$ gradle init\n```\n\nДалее нужно ответить на несколько вопросов и дождаться окончания инициализации.\nПосле этого в проекте будут созданы файлы: \n- gradlew(исполняющий файл для Linux подобных систем), gradlew.bat(исполняющий файл для Windows);\n- папка gradle, в которой папка wrapper;  \nКак раз этот wrapper и запускает скрипты. Gradle использует wrapper, чтобы можно было однозначно понять версию Gradle, которая будет использоваться для сборки.  \nWrapper сам скачает эту версию Graddle, если на машине он не установлен. Поменять версию и откуда его скачивать можно в файле gradle/gradle-wrapper.properties\n- build.gradle, settings.gradle\n\nВ **settings.gradle** указано только имя проекта, для мультимодульных проектов также здесь указывается список модулей. \n\nВ **build.gradle** имеются следущие секции:\n\n- секция plugins  \nЗдесь размещается обычно плагин id: 'java', который используется для сборки java проектов;  \nЕще существует плагин java-library, он используется если вы хотите поставлять ваше приложение как библиотеку.\n\n```groovy\nplugins {\n    id 'java'\n}\n```\n\n- секция repositories  \nЗдесь можно задать url репозитория из которого будут скачиваться зависимости. \n```groovy\nrepositories {\n    maven{\n        url = uri('https://repo.maven.apache.org/maven2/')\n    }\n}\n```\n\nДля стандартного Maven репозитория есть алиас mavenCentral().\n\n```groovy\nrepositories {\n    mavenCentral()\n}\n```\n\nТакже в build.gradle, как и в Maven содержатся group, version, description, java.sourceCompatibility, но в отличие от Maven их указывать не обязательно Gradle сможет сам сгенерировать эти данные.\nПосле компиляции нам доступны таски. В блоке verification есть таска test, которая будет запускать наши тесты. \n\n- секция dependencies  \n\nЕсть несколько типов зависимостей:\n- implementation - зависимость доступна и в main и в test директориях\n- testImplementation - зависимость доступна только в test директории\n- testAnnitationProcessor - зависимость, которая генерирует код в рантайме на основе аннотаций, требуется например для lombok\n- compileOnly - deprecated метод, вместо него нужно использовать implementation или testImplementation\n\nПосле названия метода указывается адрес зависимости, координаты адреса разделяются двоеточием - group:name:version.\n\n```groovy\ndependencies {\n    implementation 'com.codeborne:selenide:6.6.3'\n    testImplementation 'org.junit.jupiter:junit-jupiter:5.8.2'\n    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.8.2'\n    testImplementation 'org.projectlombok:lombok:1.18.24'\n    testAnnotationProcessor 'org.projectlombok:lombok:1.18.24'\n}\n```\n\nЧтобы после билда запустились тесты, нужно указать каким движком нужно запустить тесты.\n\n```groovy\ntest {\n    useJUnitPlatform() //для запуска тестов с помощью JUnit5\n}\n```\n\nКогда зависимость требует какой то сложной конфигурацией она зачастую реализуется плагином. Тогда достаточно подключить плагин и не нужно добавлять несколько зависимостей.\n\nВместо testAnnotationProcessor которую мы прописывали для lombok можно добавить плагин.\n\n```groovy\nplugins {\n    id 'io.freefair.lombok' version'5.3.0'\n}\n```\n\n## Custom task\n\nДля добавления своей таски используется коллекция tasks и новые таски в нее добавляются с помощью методы register. В метод register нужно передать название таски(по этому названию мы в последствии сможем обращаться к этой таске)\nвторой параметр опционален, в него можно передать тип таски можно использовать стандартный тип Test который был добавлен Java плагином. \n\n### Таска для запуска тестов из определенной директории\nОтфильтровать тесты которые будут запускаться можно с помощью блока filter в нем есть метод includeTestsMatching.\nНа вход этому методу можно передать wildcard - часть пути до наших тестов со звездочкой. Путь - это имя модуля, пакета, класса в котором тесты находятся.\n\n```\nsrc\n├── main\n    ├── java\n        ├── simple\n            ├── automation\n├── test\n    ├── java\n        ├── rest\n        ├── utils\n        ├── web\n            ├── findby\n            ├── simple\n```\n\n```groovy\ntasks.register('webtests', Test).configure() {\n    filter {\n        includeTestsMatching(\"web.simple*\")\n    }\n}\n```\n\n### Указываем платформу для запуска тестов из Custom Tasks \n\nЧтобы не прописывать в каждой таске, что она должна запускаться с помощью Junit можно выполнить одну настройку для всех тасок с типом test. \nДля этого на контейнере tasks используем метод withType, который выберет все таски с типом Test, и внутри конфигурационного блока используем useJUnitPlatform().\n\n```groovy\ntasks.withType(Test) {\n    useJUnitPlatform()\n}\n```\n\n### Зауск тестов из Custom Task\nВыполняем запуск тестов webtests командой:\n\n```\n$ ./gradlew webtests\n```\n\n### Добавляем еще одну custom таску\nАналогично можно настроить запуск для rest тестов:\n\n```groovy\ntasks.register('resttests', Test).configure() {\n    filter {\n        includeTestsMatching(\"rest*\")\n    }\n}\n```\n\n### Добавляем зависимость одной таски от другой\nБывает что rest тесты могут использоваться при выполнении web тестов и зачастую бывает удобно прогонять web тесты только если прошли rest тесты.\nДля этого в Gradle есть метод dependsOn с аргументом в виде названия таска, от которой зависит текущая таска. \n\n```groovy\ntasks.register('webtests', Test).configure() {\n    filter {\n        includeTestsMatching(\"web.simple*\")\n    }\n    dependsOn 'resttests'\n}\n```\n\nСоответсвенно, при запуске web тестов будут также запущены rest тесты и они выполнятся только если rest тесты пройдут. \n\n### Запуск независимых тасок в одном скоупе\nНо если у нас rest и web тесты работают независимо как разные модули или части системы, мы можем создать еще один таск regress, который будет запускать и те и другие тесты. Используем тот же метод dependsOn но уаазываем и web и rest тесты.\n\n```groovy\ntasks.register('regress') {\n    dependsOn 'webtests'\n    dependsOn 'resttests'\n}\n```\n\nНо в таком виде запуска мы не знаем в каком порядке запустятся эти таски. \n\n### Настраиваем порядок запуска тасок\nЕсли мы хотим определить порядок, например, чтобы web тесты запускались после rest тестов, мы можем использовать метод mustRunAfter или shouldRunAfter(является менее строгим и не запускает тесты если из-за зависимости образуется петля).\nЧтобы найти ранее созданный таск используем метод getByName и из него запускаем mustRunAfter с аргументом ввиде названия таски после которой нужно запускать.\n\n```groovy\ntasks.register('regress') {\n    dependsOn 'webtests'\n    dependsOn 'resttests'\n    \n    tasks.getByName('webtests').mustRunAfter('resttests')\n}\n```\n\nЛибо при создании таска можно сохранить ее в переменную и тогда можно использовать эти переменные для вызова mustRunAfter.\n```groovy\ndef webtests = tasks.register('webtests', Test).configure() {\n    filter {\n        includeTestsMatching(\"web.simple*\")\n    }\n}\n\ndef resttests = tasks.register('resttests', Test).configure() {\n    filter {\n        includeTestsMatching(\"rest*\")\n    }\n}\n\ntasks.register('regress') {\n    dependsOn 'webtests'\n    dependsOn 'resttests'\n\n    webtests.mustRunAfter(resttests)\n}\n```\n\n### Запуск тестов из директории main\nЕсли по какой то причине тесты оказались не в папке test, а в папке main, то по умолчанию Gradle найти там тесты не может. Поэтому для того чтобы указать нестандартное место исходников можно использовать блок sourceSets.\n\n1. Добавляем новый sourceSet\n\nДля создания нового сета, просто пишем имя сета и скобку, внутри добавляем блок java чтобы указать свойства которые были добавлены java плагином, compileClasspath и runtimeClasspath, добавляем через += чтобы не затирать текущие значения. \nДобавляем туда путь к папке main(если тесты лежат в папке main) - main.output. Чтобы указать где взять исходники используем свойство srcDir. \n\n```groovy\nsourceSets {\n    maintests {\n        java {\n            compileClasspath += main.output\n            runtimeClasspath += main.output\n        }\n        srcDir = file(\"src/main/java/simple/automation\")\n    }\n}\n```\n\n2. Настраиваем зависимости для добавленного sourceSet\n\nТакже нам нужны зависимости из блока dependencies, по умолчанию они в блок sourceSet не попадают.\nДля этого используется блок configurations, в нем указываем имя нашего sourceSet и без пробела пишем Implementation или RuntimeOnly. \nДалее с помощью метода extendsFrom можем указать, что зависимости нужно брать стандартные из testImplementation и testRuntimeOnly.\n\n\n```groovy\nconfigurations{\n    maintestsImplementation.extendsFrom(testImplementation)\n    maintestsRuntimeOnly.extendsFrom(testRuntimeOnly)\n}\n```\n\n3. Добавляем таск для запуска тестов, используя sourceSet\n\nСоздаем таск для запуска псевдотестов и указываем, что нужно использовать наш кастомный sourceSet.\n\n```groovy\ntasks.register('pseudotests', Test){\n    testClassesDirs = sourceSets.maintests.output.classesDirs\n    classPath = sourceSets.maintests.runtimeClasspath\n}\n```\n\n4. Добавляем фильтрацию по тегам JUnit\n\nТеперь нужно отфильтровать псевдотесты чтобы запускались только они. Сделать как в предыдущих тасках мы не можем потому что по имени package simple.automation будут запущены также и web тесты.\nНо можно использовать фильтрацию по тегам Junit. Для этого вызываем метод useJUnitPlatform, но к нему добавляем конфигурационный блок includeTags и тег методов или классов которые хотите запустить.\n\n```groovy\ntasks.register('pseudotests', Test){\n    testClassesDirs = sourceSets.maintests.output.classesDirs\n    classPath = sourceSets.maintests.runtimeClasspath\n\n    useJUnitPlatform{\n        includeTags \"pseudo\"\n    }\n}\n```\n\n### Запуск тестов с логированием\nЧтобы добавить уровень логирования INFO при запуске gradlew нужно добавить ключ -i.\nТаком образом мы увидим сообщения которые выводятся в консоль из тестов.\n\n```\n$ ./gradlew -i pseudotests\n```\n\n### Отключаем инкрементальный билд при запуске\nНо сразу мы можем их не увидеть из-за инкрементального билда.\nТак как между запусками исходники тестов не поменялись Gradle просто не запустит их.\nЧтобы они запустились перед таской с тестами запустим также таску clean. Это актуально для запуска тестов из контекста main.\nЕсли запускаются тесты из директории test то нужно использовать таску cleanTest.\n\n```\n$ ./gradlew -i clean pseudotests\n```\n\n### Отключаем инкрементальный билд глобально при настройке таски\nЧтобы каждый раз не вызывать clean таску можно установить значение upToDateWhen в знасение false для всех тасок с типом Test.\n\n```groovy\ntasks.withType(Test) {\n    useJUnitPlatform()\n    outputs.upToDateWhen {false}\n}\n```\n\nЕсли запускаетя несколько независимых тасок с тестами, то Gradle по умолчанию останавливает выполнение на первом упавшем тесте. \nМожно настроить чтобы он все равно переходил к следущей задаче даже если упала предыдущая.\nДля этого можно при запуске добавить ключ --continue\n\n```\n$ ./gradlew --continue resttests webtests\n```\n\n### Отключаем стандартную таску test при билде\n\nДля этого нужно в блоке test присвоить свойству enabled значение false\n\n```groovy\ntest {\n    enabled = false\n}\n``` \n\n### Порядок выполнения build скрипта \n\n### Как добавить кастомные экшены к таскам\n\nСоздаем еще одну таску, но не указываем тип. В этом случае у таски будет тип DefaultTask и к ней не будет привязано никаких экшенов.\nВыводить текст в консоль можно стандартной командой println, но для реального логирования лучше использовать нормальные логгеры.\nДобавим вывод текста в блок конфигурирования таски, а также перед таской и после нее.\nЧтобы добавить кастомные экшены в таску можно использовать блок doFirst - это действие которое будет выполнено перед стандартными экшенами.\nВ нашем случае таких экшенов нет а для тасок с типом Test таким стандартным экшеном был запуск тестов.\nЕще мы можем использовать блок doLast - запускает кастомные экшены после стандартных. И doFirst и doLast можно использовать несколько раз, тогда они будут исполняться в указанном порядке. \n\nПосле запуска по тексту в консоли мы видим порядок выполнения.\n\n```groovy\nprintln \"from build script root\"\ntasks.register(\"gradleTest\").configure{\n    println \"from task root\"\n    doFirst {\n        println \"from do first\"\n    }\n    doLast {\n        println \"from do last\"\n    }\n    doLast {\n        println \"from do last 2\"\n    }\n}\nprintln \"from build script root 2\"\n```\n\nРезультат выполнения:\n\n```console\n$ ./gradlew clean gradleTest\n\n> Configure project :\nfrom build script root\nfrom build script root 2\nfrom task root\n\n> Task :gradleTest\nfrom do first\nfrom do last\nfrom do last 2\n\nBUILD SUCCESSFUL in 637ms\n2 actionable tasks: 1 executed, 1 up-to-date\n```\n\nСначала вполняется код конфигурации, затем код конфигурации самой таски (код внутри таски вне блоков doFirst и doLast), \nа уже дальше выполняются экшены сначала doFirst, потом doLast в порядке в котором они указаны в скрипте.\n\n> Стоит иметь ввиду если бы у нас был многомодульный проект, то сначала вполнился бы код конфигурации из всех build скриптов всех модулей.\n\nТип таски это прсто класс. Можно создать свой тип. \nДля этого используется метод с аннотацией @TaskAction, при этом класс должен наследоваться от DefaultTask.\n\n```groovy\nclass CustomTask extends DefaultTask{\n    @TaskAction\n    def customAction(){\n        println \"from custom action\"\n    }\n}\n```\n\nТеперь можно указать наш кастомный тип при регистрации таски. И теперь между doFirst и doLast экшенами выполнился наш кастомный экшен.\n\n```groovy\nprintln \"from build script root\"\ntasks.register(\"gradleTest\", CustomTask).configure{\n    println \"from task root\"\n    doFirst {\n        println \"from do first\"\n    }\n    doLast {\n        println \"from do last\"\n    }\n    doLast {\n        println \"from do last 2\"\n    }\n}\nprintln \"from build script root 2\"\n```\n\n```console\n$ ./gradlew clean gradleTest\n\n> Configure project :\nfrom build script root\nfrom build script root 2\nfrom task root\n\n> Task :gradleTest\nfrom do first\nfrom custom action\nfrom do last\nfrom do last 2\n\nBUILD SUCCESSFUL in 1s\n2 actionable tasks: 1 executed, 1 up-to-date\n```\n\nТаск может состоять из input, actions, output. Добавим input в наш тип. Это можно сделать с помощью переменной с аннотацией @Input.\nПрисвоим ей дефолтное значение и будем использовать в нашем экшене. Теперь стандартный экшен использует значение из input'а \nи мы можем этот input переопределить в конфигурации самой таски. \n\n```groovy\nprintln \"from build script root\"\ntasks.register(\"gradleTest\", CustomTask).configure{\n    input = \"overrided\"\n    println \"from task root\"\n    doFirst {\n        println \"from do first\"\n    }\n    doLast {\n        println \"from do last\"\n    }\n    doLast {\n        println \"from do last 2\"\n    }\n}\nprintln \"from build script root 2\"\n\n\nclass CustomTask extends DefaultTask{\n    @Input\n    String input = \"default\"\n\n    @TaskAction\n    def customAction(){\n        println \"from custom action with $input\"\n    }\n}\n```\n\nПосле прогона тестов в build/test-results складывается xml отчет JUnit о прогоне тестов, а в папку reports сгенерированный из него html отчет.\nТакже есть тип таски zip позволяет что-нибудь заархивировать.\n\nИмя итогового архива задается через переменную archiveFileName, с помощью distinationDirectory указываем куда будет сложен этот архив и через\nметод from указываем какую именно папку заархивировать. Чтобы указать несколько папок используйте несколько строчек from. \n\nТаска чтобы заархивировать отчет:\n\n```groovy\ntasks.register(\"zipReport\", Zip).configure{\n    archiveFileName = 'report.zip'\n    distinationDirectory = file(\"$buildDir/reports\")\n    from \"$buildDir/reports/tests\"\n}\n```\n\nТакже потом его нужно куда нибудь скопировать. Для этого есть тип таски Copy. В ней указываем через from откуда взять файл(также можно указать несколько from),\nа в into указываем куда скопировать. \n\n```groovy\ntasks.register('copyReport', Copy).configure{\n    from file(\"$buildDir/reports/report.zip\")\n    into file(\"out\")\n}\n```\n\nЕще одна полезная таска это jar - позволяет заархивировать приложение в jar файл. \nУ него в блоке manifest в свойстве attributes можно задать атрибут Main-Class который указыывает класс в котром находится исполняемый метод main \nа в блоке from откуда взять скомпилированные классы \n\nJar собирается в папку build/libs и его можно запустить через команду java -jar \n\n```groovy\njar {\n    manifest {\n        attributes \"Main-Class\": \"simple.automation.Main\"\n    }\n    from {\n        configurations.compile.collect { it.isDirectory() ? it : zipTree(it) }\n    }\n}\n```\n\n## Источник информации \nhttps://www.youtube.com/watch?v=qYIz6URLxbU\n\n## TODO\n\nhttps://www.youtube.com/watch?v=WOBok2u-SL8\n\nhttps://www.youtube.com/watch?v=NZJTYPLb0iE","date":"2022-06-17T00:00:00.000Z","path":"/gradle/","icon":"fas fa-robot","image":"null","order":null,"category":{"title":"automation","path":"/category/automation/"},"tags":[{"title":"Автоматизация тестирования","path":"/tag/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F/"}],"headings":[{"value":"project","anchor":"#project"},{"value":"Сборка Java приложения","anchor":"#сборка-java-приложения"},{"value":"Custom task","anchor":"#custom-task"},{"value":"Источник информации","anchor":"#источник-информации"},{"value":"TODO","anchor":"#todo"}]}},{"node":{"id":"7f1278f719588578f4f4a80461d43b8a","title":"JUnit 5","content":"\nЗачастую для тестов нужно сделать какие то действия: до тестов, после тестов или перед каждым тестом.\nДля этих целей используются такие тест ранеры как JUnit или TestNG.\n\nJUnit5 разделен на 3 глобальных модулей: Platform, Jupiter, Vintage.\n\nPlatform - база которая позволяет строить свои собственные фреймворки для запуска тестов. На основе этого модуля сделали интеграцию с Intellij Idea, maven, gradle и сам Junit5. Сюда же входит лаунчер который позволяет запускать тесты из консоли. \n\nJupiter - прораммный код самого Junit5. Также этот модуль содержит новую концепцию extensions(расширений), которая заменила ранеры и правила из JUnit4. \n\nVintage - модуль для обратной совместимости. Позволяет запускать тесты написанных на JUnit3 и JUnit4. \n\n## Подключение зависимостей\n\nДля подключения JUnit5 добавляем в зависимости модуль Platform(junit-platform-launcher) и движок Jupiter(junit-jupiter-engine)\n\n### Maven\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.junit.platform/junit-platform-launcher -->\n<dependency>\n    <groupId>org.junit.platform</groupId>\n    <artifactId>junit-platform-launcher</artifactId>\n    <version>1.10.2</version>\n    <scope>test</scope>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.junit.jupiter/junit-jupiter-engine -->\n<dependency>\n    <groupId>org.junit.jupiter</groupId>\n    <artifactId>junit-jupiter-engine</artifactId>\n    <version>5.10.2</version>\n    <scope>test</scope>\n</dependency>\n```\n\n### Gradle\n\n```groovy\n// https://mvnrepository.com/artifact/org.junit.platform/junit-platform-launcher\ntestImplementation 'org.junit.platform:junit-platform-launcher:1.10.2'\n\n// https://mvnrepository.com/artifact/org.junit.jupiter/junit-jupiter-engine\ntestImplementation 'org.junit.jupiter:junit-jupiter-engine:5.10.2'\n```\n\nПосле добавления к методу аннотации @Test в IDEA появляется кнопка play соответсвенно этот метод теперь можно запустить и его выполнит движок Junit. Если запустить класс то будут выполнены все тестовые методы из данного класса.\n\nМожно определять тестовые методы без модификатора (public, private, protected).\n\n```java\n@Test\nvoid someTest(){\n    assertTrue(true);\n}\n```\n\n## Аннотации JUnit 5\nJUnit 5 предлагает следующие аннотации для написания тестов.\n\n| Аннотации | Описание |\n| --- | --- |\n| @BeforeEach | Аннотированный метод будет запускаться перед каждым тестовым методом в тестовом классе. |\n| @AfterEach | Аннотированный метод будет запускаться после каждого тестового метода в тестовом классе. |\n| @BeforeAll | Аннотированный метод будет запущен перед всеми тестовыми методами в тестовом классе. Этот метод должен быть статическим. |\n| @AfterAll | Аннотированный метод будет запущен после всех тестовых методов в тестовом классе. Этот метод должен быть статическим. |\n| @Test | Он используется, чтобы пометить метод как тест junit. |\n| @DisplayName | Используется для предоставления любого настраиваемого отображаемого имени для тестового класса или тестового метода |\n| @Disable | Он используется для отключения или игнорирования тестового класса или тестового метода из набора тестов. |\n| @Nested | Используется для создания вложенных тестовых классов |\n| @Tag | Пометьте методы тестирования или классы тестов тегами для обнаружения и фильтрации тестов. |\n| @TestFactory | Отметить метод - это тестовая фабрика для динамических тестов. |\n\n\n### @BeforeAll\n\nАннотация @BoforeAll используются для указания о том, что аннотированный метод должен быть выполнен перед всеми @Test, @RepeatedTest, @ParameterizedTest и @TestFactory методами в текущем классе.\n\nПо умолчанию тестовые методы будут выполняться в том же потоке, что и аннотированный @BeforeAll метод.\n\nАннотированный @BeforeAll метод ДОЛЖЕН быть статическим методом в тестовом классе.\n\n```java\n@BeforeAll\npublic static void init(){\n    System.out.println(\"BeforeAll init() method called\");\n}\n```\n\nИли мы можем применить эту аннотацию к default методам интерфейса, если тестовый интерфейс или тестовый класс аннотированы с помощью @TestInstance(Lifecycle.PER_CLASS).\n\n```java\n@TestInstance(Lifecycle.PER_CLASS)\ninterface TestLifecycleLogger {\n\n    @BeforeAll\n    default void beforeAllTests() {\n        //\n    }\n}\n```\n\nЕсли этого не сделать, JUnit выдаст ошибку времени выполнения типа JUnitException.\n\n```java\norg.junit.platform.commons.JUnitException: \n@BeforeAll method 'public void com.howtodoinjava.junit5.examples. \nJUnit5AnnotationsExample.init()' must be static.\nat org.junit.jupiter.engine.descriptor. \nLifecycleMethodUtils.assertStatic(LifecycleMethodUtils.java:66)\n```\n\n#### @BeforeAll в родительском и дочернем классах\n\n@BeforeAll методы наследуются от родительских классов (или интерфейсов), если они не скрыты или не переопределены. \n\nКроме того, @BeforeAll методы из родительских классов (или интерфейсов) будут выполняться перед @BeforeAll методами в дочерних классах.\n\n### @BeforeEach\n\nАннотация @BeforeEach используется для обозначения того, что аннотированный метод должен выполняться перед каждым методом @Test, @RepeatedTest, @ParameterizedTest, или @TestFactory в текущем классе.\n\nАннотация JUnit 5 @BeforeEach является одним из методов жизненного цикла и заменяет аннотацию @Before в JUnit 4.\n\nПо умолчанию тестовые методы будут выполняться в том же потоке, что и аннотированный @BeforeEach метод.\n\n```java\n@BeforeEach\npublic void initEach(){\n     //test setup code\n}\n\n@Test\nvoid succeedingTest() {\n    //test code and assertions\n}\n```\n\nАннотированный @BeforeEach метод НЕ ДОЛЖЕН быть статическим, иначе он вызовет ошибку времени выполнения.\n\n```java\n@BeforeEach\npublic static void initEach(){\n     //test setup code\n}\n\n//Error\n\n\norg.junit.platform.commons.JUnitException: @BeforeEach method 'public static void com.howtodoinjava.junit5.examples. JUnit5AnnotationsExample.initEach()' must not be static.\nat org.junit.jupiter.engine.descriptor. LifecycleMethodUtils.assertNonStatic(LifecycleMethodUtils.java:73)\n```\n\n#### @BeforeEach в родительском и дочернем классах\n\nМетод @BeforeEach наследуется от родительских классов (или интерфейсов) до тех пор, пока они не скрыты или не  переопределены. \n\nКроме того, каждый метод с аннотацией @Before из родительских классов (или интерфейсов) будет выполняться перед каждым методом с аннотацией @Before в дочерних классах.\n\n## @ParameterizedTest\n\nИспользуется, чтобы выполнить тест несколько раз, но с разными аргументами. \n\n1. Включите зависимость junit-jupiter-params, чтобы использовать параметризованные тесты.\n\nПоследнюю версию можно найти по этой ссылке https://mvnrepository.com/artifact/org.junit.jupiter/junit-jupiter-params.\n\npom.xml\n\n```java\n<dependency>\n    <groupId>org.junit.jupiter</groupId>\n    <artifactId>junit-jupiter-params</artifactId>\n    <version>${junit-version}</version>\n    <scope>test</scope>\n</dependency>\n```\n\n2. Нам не нужно использовать аннотацию @Test, вместо этого в таких тестах используется только аннотация @ParameterizedTest.\nМы должны объявить по крайней мере один источник аргументов, предоставляющий аргументы для каждого вызова, которые будут использоваться в тестовом методе.\n\nВ данном примере testPalindrome будет вызываться 2 раза для каждой строки, указанной в аннотации @ValueSource. Мы получаем доступ к аргументу, используя параметр word метода.\n\nИспользуйте аргумент name в аннотации @ParameterizedTest, чтобы настроить отображаемое сообщение.\n\n```java\npublic class ParameterizedTests \n{\n    public boolean isPalindrome(String s) {\n        return s == null ? false : StringUtils.reverse(s).equals(s);\n    }\n    \n    @ParameterizedTest(name = \"{index} - {0} is a palindrome\")\n    @ValueSource(strings = { \"12321\", \"pop\" })\n    void testPalindrome(String word) {\n        assertTrue(isPalindrome(word));\n    }\n}\n```\n\n### Источники тестовых аргументов\n\n#### Аннотация @ValueSource\nИспользуйте @ValueSource для простых буквальных значений, таких как примитивы и строки.\n\nОна определяет один массив значений и может использоваться только для предоставления одного аргумента для каждого параметризованного вызова теста.\n\nJava поддерживает автобоксирование, поэтому мы также можем использовать литералы в их классах-оболочках.\n\nМы не можем передавать null в качестве аргумента даже для типов String и Class.\n\n```java\n@ParameterizedTest\n@ValueSource(ints = { 1, 2, 3 })\nvoid testMethod(int argument) {\n    //test code\n}\n\n@ParameterizedTest\n@ValueSource(ints = { 1, 2, 3 })\nvoid testMethodWithAutoboxing(Integer argument) {\n    //test code\n}\n```\n\n#### Аннотация @NullSource\n\nОна предоставляет единственный null аргумент методу, аннотированному @ParameterizedTest.\n\n```java\n@ParameterizedTest\n@NullSource\nvoid testMethodNullSource(Integer argument) {\n    assertTrue(argument == null);\n}\n```\n\n#### Аннотация @EmptySource\nОна предоставляет метод, аннотированный @ParameterizedTest, с единственным пустым аргументом следующих типов:\n\njava.lang.String\n\njava.util.List\n\njava.util.Set\n\njava.util.Map\n\nпримитивные массивы (например, int [])\n\nмассивы объектов (например, String [])\n\n```java\n@ParameterizedTest\n@EmptySource\nvoid testMethodEmptySource(String argument) {\n    assertTrue(StringUtils.isEmpty(argument));\n}\n```\n\n#### Аннотация @NullAndEmptySource\nОна сочетает в себе функциональность @NullSource и @EmptySource. В данном примере тестовый метод будет вызываться два раза - сначала со значением null, а затем со значением empty.\n\n```java\n@ParameterizedTest\n@NullAndEmptySource\nvoid testMethodNullAndEmptySource(String argument) {\n    assertTrue(StringUtils.isEmpty(argument));\n}\n\n```\n\n##### Проверка null и non-null значений в одном тесте\n\nМы уже знаем, что аннотация @ValueSource не поддерживает значение null.\n\nТаким образом, используя @NullSource и @EmptySource в аннотации @ValueSource, мы можем тестировать null, non-null и пустые значения в одном и том же тесте.\n\n#### Аннотация @EnumSource\nЭто удобный способ использования Enum констант. Метод тестирования будет вызываться для каждой константы перечисления за раз.\n\nВ данном примере тестовый метод будет вызываться 4 раза, по одному разу для каждой Enum константы.\n\n```java\nenum Direction {\n    EAST, WEST, NORTH, SOUTH\n}\n\n@ParameterizedTest\n@EnumSource(Direction.class)\nvoid testWithEnumSource(Direction d) {\n    assertNotNull(d);\n}\n```\n\n#### Аннотация @MethodSource\nОна используется для ссылки на один или несколько фабричных методов тестового класса или внешних классов. Фабричный метод должен генерировать поток аргументов, где каждый аргумент в потоке будет использоваться методом, аннотированным @ParameterizedTest.\n\nФабричный метод должен быть static, если тестовый класс не аннотирован с помощью @TestInstance(Lifecycle.PER_CLASS).\n\nКроме того, фабричный метод не должен принимать аргументы.\n\n```java\n@ParameterizedTest\n@MethodSource(\"argsProviderFactory\")\nvoid testWithMethodSource(String argument) {\n    assertNotNull(argument);\n}\n\nstatic Stream<String> argsProviderFactory() {\n    return Stream.of(\"alex\", \"brian\");\n}\n```\n\nЕсли мы явно не предоставим имя фабричного метода через @MethodSource, JUnit будет искать фабричный метод, имя которого по умолчанию совпадает с именем текущего метода с аннотацией @ParameterizedTest.\n\nПоэтому, в примере, если мы не предоставим имя метода argsProviderFactory в аннотации @MethodSource, Junit будет искать имя метода testWithMethodSource с возвращаемым типом `Stream<String>`.\n\n```java\n@ParameterizedTest\n@MethodSource\nvoid testWithMethodSource(String argument) {\n    assertNotNull(argument);\n}\n\nstatic Stream<String> testWithMethodSource() {\n    return Stream.of(\"alex\", \"brian\");\n}\n```\n\nТакже поддерживаются потоки для примитивных типов (DoubleStream, IntStream и LongStream).\n\n```java\n@ParameterizedTest\n@MethodSource(\"argsProviderFactory\")\nvoid testWithMethodSource(int argument) {\n    assertNotEquals(9, argument);\n}\n\nstatic IntStream argsProviderFactory() {\n    return IntStream.range(0, 10);\n}\n```\n\n#### Аннотация @CsvSource\nЭта аннотация позволяет нам задавать списки аргументов как значения, разделенные запятыми. Каждый CSV токен представляет собой строку CSV и приводит к одному вызову параметризованного теста.\n\nЗадайте для свойства ignoreLeadingAndTrailingWhitespace значение true или false, указывающее на то, что Junit должен принимать или игнорировать пробелы в CSV токенах.\n\n```java\n@ParameterizedTest\n@CsvSource(value = {\n    \"alex, 30\",\n    \"brian, 35\",\n    \"charles, 40\"\n}, ignoreLeadingAndTrailingWhitespace = true)\nvoid testWithCsvSource(String name, int age) {\n    assertNotNull(name);\n    assertTrue(age > 0);\n}\n```\n\n#### Аннотация @CsvFileSource\nЭта аннотация очень похожа на @CsvSource за исключением того, что мы читаем токены CSV из файла вместо чтения токенов в исходном тексте. CSV файл можно прочитать по classpath или из локальной файловой системы.\n\nРазделителем по умолчанию является запятая (,), но мы можем использовать другой символ, установив атрибут разделителя.\n\nОбратите внимание, что любая строка, начинающаяся с символа #, будет интерпретироваться как комментарий и игнорироваться.\n\n```java\n@ParameterizedTest\n@CsvFileSource(resources = \"employeeData.csv\", numLinesToSkip = 0)\nvoid testWithCsvFileSource(String name, int age) {\n    assertNotNull(name);\n    assertTrue(age > 0);\n}\n```\n\n#### Аннотация @ArgumentsSource\nАннотацию @ArgumentsSource можно использовать для указания настраиваемого многоразового поставщика аргументов ArgumentsProvider.\n\n```java\n@ParameterizedTest(name = \"{index} - {0} is older than 40\")\n@ArgumentsSource(EmployeesArgumentsProvider.class)\nvoid isEmployeeAgeGreaterThan40(Employee e) {\n    assertTrue(Period.between(e.getDob(), LocalDate.now()).get(ChronoUnit.YEARS) > 40);\n}\n\nclass EmployeesArgumentsProvider implements ArgumentsProvider {\n    @Override\n    public Stream<? extends Arguments> provideArguments(ExtensionContext context) {\n        return Stream.of(\n          Arguments.of(new Employee(1, \"Alex\", LocalDate.of(1980, 2, 3))),\n          Arguments.of(new Employee(2, \"Brian\", LocalDate.of(1979, 2, 3))),\n          Arguments.of(new Employee(3, \"Charles\", LocalDate.of(1978, 2, 3)))\n        );\n    }\n}\n```\n\n### Параметризованные тесты с несколькими аргументами\n\nЧтобы написать тесты, которые могут использовать несколько аргументов, мы можем использовать следующие аннотации:\n\n#### Аннотация @CsvSource\nКак показано в предыдущем разделе 3.7, с помощью аннотации @CsvSource мы можем предоставить множество литералов и простых типов аргументов.\n\nНам нужно предоставить все аргументы в одном токене CSV, а затем определить соответствующие аргументы метода.\n\n```java\n@ParameterizedTest\n@CsvSource({\n    \"alex, 30, HR, Active\",\n    \"brian, 35, Technology, Active\",\n    \"charles, 40, Finance, Purged\"\n})\nvoid testWithCsvSource(String name, int age, String department, String status) {\n    //test code\n}\n```\n\n#### Интерфейс ArgumentsProvider\nЧтобы предоставить несколько тестовых аргументов сложных или настраиваемых типов, мы должны использовать аннотацию @ArgumentsSource с аннотацией ArgumentsProvider.\n\nВ примере мы передаем три аргумента метода тестирования testArgumentsSource, типов Employee, LocalDateи enum константы типа Direction.\n\n```java\n@ParameterizedTest\n@ArgumentsSource(EmployeesArgumentsProvider.class)\nvoid testArgumentsSource(Employee e, LocalDate date, Direction d) {\n    assertTrue(Period.between(e.getDob(), LocalDate.now()).get(ChronoUnit.YEARS) > 40);\n    assertNotNull(date);\n    assertNotNull(d);\n}\n\nclass EmployeesArgumentsProvider implements ArgumentsProvider {\n    @Override\n    public Stream<? extends Arguments> provideArguments(ExtensionContext context) {\n        return Stream.of(\n          Arguments.of(new Employee(1, \"Alex\", \n                  LocalDate.of(1980, 2, 3)), LocalDate.now(), Direction.EAST),\n          Arguments.of(new Employee(2, \"Brian\", \n                  LocalDate.of(1979, 2, 3)), LocalDate.now(), Direction.NORTH),\n          Arguments.of(new Employee(3, \"Charles\", \n                  LocalDate.of(1978, 2, 3)), LocalDate.now(), Direction.SOUTH)\n        );\n    }\n```\n\n## Build tool support\n\n```groovy\ntest {\n    useJUnitPlatform {\n        includeTags 'fast', 'smoke'\n        excludeTags 'slow', 'ci'\n\n        include 'org/foo/**'\n        exclude 'org/boo/**'\n    }\n}\n```\n\nhttps://www.youtube.com/watch?v=RAOAcq97KZM\n\nhttps://www.youtube.com/watch?v=w1ey2zjf3-s\n\nhttps://www.youtube.com/watch?v=DAszLeWMsqU\n\nhttps://www.youtube.com/watch?v=751gMXH-lEE\n\nhttps://www.youtube.com/watch?v=r-8EGXMFJaw\n\nhttps://www.youtube.com/watch?v=ZIkIUCyJBGU\n\nhttps://www.youtube.com/watch?v=3pOjh6O7-cg\n\nhttps://www.youtube.com/watch?v=W1INR0I3FCo&list=PLnh8EajVFTl5AqvBosxUefReW4nC35P0x","date":"2022-06-18T00:00:00.000Z","path":"/j-unit-5/","icon":"fas fa-robot","image":"null","order":null,"category":{"title":"automation","path":"/category/automation/"},"tags":[{"title":"Автоматизация тестирования","path":"/tag/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F/"}],"headings":[{"value":"Подключение зависимостей","anchor":"#подключение-зависимостей"},{"value":"Аннотации JUnit 5","anchor":"#аннотации-junit-5"},{"value":"@ParameterizedTest","anchor":"#parameterizedtest"},{"value":"Build tool support","anchor":"#build-tool-support"}]}},{"node":{"id":"6cc7b17cf4d6b9086536772cd0489771","title":"Собеседование в 2ГИС","content":"\n## Официальная инструкция\n\nhttps://qa-welcome.2gis.ru/\n\n## Автоматизация\n\n1. Опыт использования инструментов автоматизации:\n- [CI/CD](/ci-cd/)\n- [Docker и контейнеризация](/docker/)\n- виртуальные машины\n- языки программирования\n- [фреймворки](/frejmvorki-avtomatizaczii-testirovaniya/)  \n[Сравнение Junit и TestNG](/j-unit-vs-test-ng/)\n\n2. Применяемые подходы к автоматизации и процессы для автоматизации\n- [подходы](/podhody-k-avtomatizaczii-testirovaniya/)\n- процессы\n\n3. Сетевой стек и архитектура веб-приложений\n- сетевой стек\n- архитектура веб-приложений\n\n## Задание на собеседовании\n\n### Задача 1\n\n```java\n// Существует поле с элементами разных цветов. \n// Необходимо найти самую длинную цепочку (по горизонтали/вертикали) из элементов одного цвета, вывести ее цвет и длину. \n// Размерность поля может быть любая, кол-во цветов тоже не ограничено\n\nclass main {\n    public static void main(String[] args) {\n        String[][] table  = new String[][] {\n            {\"green\", \"green\", \"blue\", \"red\"},\n            {\"blue\",  \"green\", \"blue\", \"blue\"},\n            {\"green\", \"red\",   \"red\",  \"red\"}\n        };\n\n```\n\n### Задача 2\n\nSQL-запрос, чтобы из 1000 студентов отобрать десять человек с лучшими оценками","date":"2022-08-04T00:00:00.000Z","path":"/sobesedovanie-v-2-gis/","icon":"fas fa-robot","image":"null","order":1,"category":{"title":"interview","path":"/category/interview/"},"tags":[{"title":"Автоматизация тестирования","path":"/tag/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F/"},{"title":"собеседование","path":"/tag/%D1%81%D0%BE%D0%B1%D0%B5%D1%81%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5/"},{"title":"2ГИС","path":"/tag/2%D0%93%D0%98%D0%A1/"}],"headings":[{"value":"Официальная инструкция","anchor":"#официальная-инструкция"},{"value":"Автоматизация","anchor":"#автоматизация"},{"value":"Задание на собеседовании","anchor":"#задание-на-собеседовании"}]}},{"node":{"id":"dfb6220aef4f7a7060af2e915f6a4522","title":"Микросервисная архитектура","content":"\n## Микросервисная архитектура\n\n### Особенности\n\n- дает простоту и независисмость деплоймента;\nМы можем деплоить каждый микросервис отдельно.\nНапример, если есть изменения в микросервисе А, то мы деплоим только его и нам не нужно передеплаивать UI или другие микросервисы;\n\n- каждый микросервис имеет одну свою собственную, как правило простую функцию;\nи как правило, поддерживается одной командой, иногда даже из 1-2 человек;\n\n- отсутсвие иерархической структуры;\nмикросервис может комуницировать с БД или с другим микросервисом, нет какой то четкой структуры.\n\n- микросервисы взаимодействуют друг с другом напрямую;\n\n### Преимущества\n\n- микросервисы взаимодействуют по очень легковесным сетевым протоколам, как правило это REST;\n\n- мы можем в пределах одного приложения использовать какие угодно технологии и языки программирования;\nнапример, один микросервис на java, а другой на nodejs и это отлично работает;\n\n- простота масштабирования микросервисной архитектуры;\n\n### Проблемы для автоматизации тестирования\n\n- каждый микросервис имеет собственную ценность для заказчика \nесли монолитное приложение мы тестируем и используем все целиком, то в тут каждый микросервис имеет свою ценность;\nи не обязательно его использовать с тем UI клиентом, который был написан изначально, клиент может захотеть использовать другой клиент, мобильный клиент или переписать UI;\nнам важно, чтобы микросервис сам по себе выполнял те функции, которые на него возложены;\n\n- проблема мертвого кода\nкогда есть микросервисы и один микросервис мы больше не используем, его заменили на другой микросервис\nпри этом если automation framework остается монолитным то возникает проблема что есть автотесты которые существую но при этом они уже не нужны.\n\n- нужно также тестировать взаимодействие между микросервисами\n\n### Архитектура для автотестирования\n- тесты на java\n- конфигурация spring\n- билд через Maven\n- BDD - Cucumber\n- взаимодействие с UI - Selenium(Selenide)\n- взаимодействие с BackEnd - RestAssured\n- хранилице тестов - Google Cloud Platform\n- управление контейнерами - Kubernetes\n- для запуска тестов - Selenoid\n- для отчетности - Report Portal, Allure\n\n**Unit тесты** пишутся разработчиками.\n\n**Integrartion тестирование** - разбито  на 2 слоя: слой клиента, который работает как аналог UI, отправляет запросы и принимает ответы\nи уровень тестов, где происходят проверки.\n\n**UI тестирование** - имеет 3 слоя: уровень страниц (pages), уровень шагов (steps), уровень тестов (tests)\n\nДалее UI тесты подключаются к Selenoid - это браузеры, которые запускаются в докер контейнерах и оркестрируются Kubernetes' ом.\nЧтобы включить ui тесты в pipeline. \n\nUI тесты и BackEnd тесты не взаимодействуют между собой, поэтому чтобы создать тестовые данные, например пользователя который будет логиниться в приложение, это нужно будет делать через UI, что не совсем удобно.\n\nДля решения этой проблемы мы подключаем клиентскую часть Backend тестов через dependency в Мавен проект UI тестов, для того чтобы создать тестовые данные или ускорить работу UI тестов(например для быстрого логина в приложение).\n\nДля проверки взаимодействия микросервисов, мы подключаем клиентскую часть backEnd тестов для микросервиса 1 к клиентской часть backend тестов микросервиса 2 и проверяем.\n\nДля предоставления результатов используется Allure репорт, он используется для внутренних нужд.\n\nДля кастомера используется Report Pirtal, где отображаются результаты со всех уровенй тестирования.\n\n#### Selenoid\n\n- доступен сразу из коробки\n\n- есть 2 решения:\n  1. деплоится на виртуальную машину\n  2. деплоится в kubernetes кластер\nесли есть cloud платформа то можно бытсро с помощью seleonoid поднять браузер в cloud'е\n\n- браузеры стартуют очень быстро (~30сек)\n\n- надежность\nбраузеры сами закрываются ничего не зависает\n\n- запись видео\n\n## Docker\n\nDocker container - экземпляр Docker Image который содержит три атрибута:\n- docker image\n- среда запуска\n- стандартный набор инструкций\n\n### Преимущества\n\n- приложения портируемые и стандартно упакованные\nзапустить можно везде где есть docker engine\n- деплоймент простой и повторяемый \n- поддержка микросервисной архитектуры\nкаждый микросервис запакован, изолирован и запускается отдельно\n\n### Tools for containers orchestration\n\n- kubernetes - самый распространненый инструмент\n- docker swarm - нативный tool\n- rancher\n- mesos\n\n#### Источник информации:\n1. ❗[Automation testing solution for micro service architecture](https://www.youtube.com/watch?v=0QVlMsObhuQ)","date":"2022-07-27T00:00:00.000Z","path":"/mikroservisnaya-arhitektura/","icon":"fas fa-robot","image":"null","order":1,"category":{"title":"testops","path":"/category/testops/"},"tags":[{"title":"Автоматизация тестирования","path":"/tag/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F/"},{"title":"микросервисы","path":"/tag/%D0%BC%D0%B8%D0%BA%D1%80%D0%BE%D1%81%D0%B5%D1%80%D0%B2%D0%B8%D1%81%D1%8B/"}],"headings":[{"value":"Микросервисная архитектура","anchor":"#микросервисная-архитектура"},{"value":"Docker","anchor":"#docker"}]}},{"node":{"id":"8254c31741f638f0043c46953a422fae","title":"CI/CD","content":"\n**CI/CD (Continuous Integration, Continuous Delivery — непрерывная интеграция и доставка)** — это технология автоматизации тестирования и доставки новых модулей разрабатываемого проекта заинтересованным сторонам (разработчикам, аналитикам, инженерам качества, конечным пользователям и др.).\n\n## Принципы CI/CD\nКонцепция непрерывной интеграции и развертывания относится к agile-методологиям разработки программного обеспечения. Ее основная цель — уделение достаточного внимания бизнес-требованиям, безопасности и качеству кода конечного продукта. В рамках подхода решаются следующие задачи:\n\n- автоматизация последовательной сборки, упаковки и тестирования программных продуктов;\n- автоматизация развертывания приложения в различных окружениях;\n- минимизация ошибок и уязвимостей программного продукта.\n\nРазработка по методике CI/CD соответствует таким основным принципам:\n- **Распределение ответственности.** Задачи и этапы разработки разделяются между членами команды или ее подгруппами (при работе над большим проектом). Рабочий процесс организуется с учетом бизнес-логистики, внедрения сквозных функций, проведения тестов, безопасности хранения данных и т.д.\n- **Сокращение рисков.** Каждый разработчик или подгруппа разработчиков должны стремиться минимизировать уязвимости и ошибки на всех этапах разработки. Для этого постоянно контролируется бизнес-логистика, проводится пользовательское тестирование продукта, оптимизируется хранение, обработка данных и т.д.\n- **Оптимизация обратной связи.** Успех проекта зависит от того, как работают друг с другом разработчики, клиенты и пользователи. Это влияет на скорость внесения в приложение корректировок и обновлений. Если сборку и тестирование можно автоматизировать, то во многих других операциях требуется участие человека. Чтобы взаимодействие происходило конструктивнее, уменьшается количество посредников между заказчиком, исполнителями и пользователями.\nСоздание рабочей среды. Для удобства совместной работы у разработчиков должно быть общее рабочее пространство. Помимо основной ветки процесса в нем должна быть побочная – в ней удобнее проводить тестирование, вносить корректировки, отслеживать отказоустойчивость и т.д.\n\nСI/CD представляет собой современную аналогию конвейерного производства. Их объединяют четкое распределение труда, непрерывный, потоковый характер рабочего процесса, параллельное выполнение сразу нескольких задач (например, кодинга и тестирования). Сегодня эта концепция является доминирующей в DevOps.\n\n## Этапы CI/CD\n**Написание кода.** Каждый разработчик создает код отведенного ему модуля и тестирует его в ручном режиме. Затем разработанный и проверенный программный блок интегрируется в основной ветке с текущей версией продукта. Как только все модули будут опубликованы в главной ветке, команда переходит к следующему этапу.\n\n**Сборка.** Заранее подобранная система контроля версий запускает автоматизированную сборку и тестирование всего продукта. Триггеры могут быть настроены автоматически или вручную. Автоматическая сборка выполняется с помощью Jenkins или другого сервера непрерывной интеграции.\n\n**Ручное тестирование.** Как только CI-сервер закончит автоматизированную сборку продукта, он передается тестировщикам на проверку. Они используют различные методики тестирования для выявления и устранения ошибок и уязвимостей программы.\n\n**Релиз.** После исправления ошибок вычищенный и отлаженный код переходит на этап релиза для клиентов. Его проверяет заказчик, возможно, с привлечением своих специалистов или ограниченной группы пользователей. По результатам проверки код отправляется на доработку или согласуется.\n\n**Развертывание.** Текущая версия программы размещается на продакшн-серверах разработчика. Заказчик может работать с программой, исследовать ее функции, искать уязвимости.\n\n**Поддержка и отслеживание.** После развертывания приложение становится доступным конечным пользователям. Параллельно этому разработчики выполняют его поддержку и одновременно мониторят реакцию пользователей, анализируют их опыт взаимодействия с программой.\n\n**Планирование.** На основании данных, полученных при изучении пользовательского опыта, разработчик подготавливает план доработок, включающий новые функции, исправление ошибок и т.д. После этого он вносит все корректировки в продукт — и цикл разработки начинается снова.\n\nТаким образом, рабочий процесс по методологии CI/CD включает как последовательные, так и параллельные этапы. Именно для распараллеливания в рабочем пространстве создается побочная ветка — в ней проще вести работу, не вмешиваясь в основной код до тех пор, пока программируемый модуль не будет готов к интеграции. Условно рабочий процесс по методологии CI/CD можно представить в виде следующей схемы:\n\n## Общий принцип CI/CD-разработки\n\n### Преимущества CI/CD\n**Сокращение сроков разработки.** Методология уменьшает время доработок до нескольких дней, в сложных проектах — недель. Это позволяет разработчикам быстрее тестировать и опробовать нововведения, а затем внедрять их в продукт раньше конкурентов.\nОтбор перспективных вариантов. Быстрое тестирование и большое количество итераций позволяют разработчику вовремя отсеивать бесперспективные варианты кода на начальных этапах. Это также способствует экономичному расходованию времени и ресурсов без их распыления на тупиковые направления.\n\n**Качество тестирования.** Сочетание ручной и автоматизированной проверки позволяет выявлять ошибки на ранних этапах разработки. Это снижает вероятность их накопления на этапе релиза, что еще больше сокращает время работы над проектом.\n\n## Недостатки CI/CD\n**Высокие требования к опыту.** Рабочий процесс в любой компании можно перевести на методологию CI/CD. Однако это требует от разработчиков как знания самой концепции на практическом уровне, так и умения быстро реорганизовать процессы в самой организации. Иными словами, CI/CD имеет достаточно большой порог вхождения в сравнении со многими традиционными методологиями.\n\n**Сложность постоянного взаимодействия.** Непрерывная интеграция и доставка программного продукта требуют от разработчиков высокой скоординированности действий. На практике это означает, что должно быть отдельное лицо, которое занимается организацией рабочего процесса и налаживанием взаимодействия между членами команды.\n\n## Инструменты для CI/CD\nТак как непрерывная интеграция и развертывание подразумевает автоматизацию многих процессов в ходе разработки, для этого созданы различные программные инструменты и сервисы:\n\n**GitLab.** Эта платформа позволяет управлять хранилищами проекта, документировать результаты тестирования и доработок, анализировать и дополнять функциональность проекта, выявлять и устранять ошибки.\n\n**Docker.** СD-система, позволяющая контейнеризировать проект, то есть упаковать его со всем окружением и зависимостями.\n\n**Travis-CI.** Сервер, который можно подключать к виртуальным репозиториям GitHub с минимальными настройками. Благодаря использованию облачных технологий его не нужно отдельно устанавливать.\n\n**Jenkins.** Один из самый популярных DevOps-инструментов, совместимый со всевозможными плагинами для адаптации под различные проекты и задачи.\n\n**PHP Censor.** CI-сервер, автоматизирующий сборку PHP-проектов. Может работать с репозиториями GitLab, Mercurial и другими, с библиотеками для тестирования Atoum, PHP Spec, Behat.\n\nВозможность оперативно вносить изменения, постоянно тестировать и дорабатывать продукт, взаимодействовать не только друг с другом, но и с клиентом — вот что делает концепцию CI/CD популярной среди разработчиков. Сегодня ее понимание и практическое освоение являются важной рекомендацией при разработке как крупных, так и небольших проектов.\n\nhttps://www.youtube.com/watch?v=7S1ndRRht6M\n\n## Вопросы\n\n### Какие стадии должны быть в любом пайплайне?\n\n- build\n- test - unit, integration tests\n- lint - metrics chacks: coverage, code analysis\n- deploy\n- system tests: api tests, ui tests\n\n### Что такое Continuous Integration и Continuous Deployment? В чем разница между Continuous Deployment и Continuous Delivery?\nContinuous Integration (CI) - непрерывная интеграция, это практика разработки программного обеспечения, при которой члены команды часто интегрируют свою работу. Интеграция это слияние новой версии кода со стабильной и проверка, что при этом ничего не сломалось. \n\nРазница между Continuous Delivery и Continuous Deployment очень маленькая. Представим два пайплайна для одного и того же приложения. В каждом есть шаги:\n\nSource Control - внесение изменений в систему контроля версий ПО\nBuild - сборка приложения и прогон unit тестов\nStaging - деплой на тестовое окружение, прогон интеграционных, нагрузочных и других тестов\nProduction - деплой на окружение с пользователями\nКаждый пайплайн запускается автоматически по триггеру из системы контроля версий. В случае Continuous Deployment каждый следующий шаг, будет выполнен автоматически если предыдущий был успешный, включая деплой на Production.\n\nЕсли же у вас Continuous Delivery, то шаги будут выполняться автоматически только в безопасной среде, а перед деплоем на Production пайплайн остановится и будет ждать ручного подтверждения. Механизм, как это будет реализовано может быть разным. От самого простого, когда ответственный человек должен зайти в пайплайн и нажать кнопку Next, до интерактивного бота с кнопками в корпоративном мессенджере.\n\nЗачем нужен ручной апрув перед деплоем на Production, ведь это тормозит пайплайн т.е. доставку фич и исправлений багов? Вопрос резонный, но ответ такой же. Не все проекты одинаковые, есть такие в которых решение о деплое на Production должно быть принято человеком ответственно и осознанно. Когда бизнес сложный, с большим количеством факторов и нельзя переложить выбор “деплоить или нет” на пару алгоритмических критериев, тогда и применяется Continuous Delivery, а не Continuous Deployment.\n\n\n52. Опишите основные этапы CI/CD.\n момент, когда триггерится сборка, например, когда разработчик сделал коммит в свою ветку, запускается процесс, который выполняется специально написанными скриптами и утилитами. Этот процесс состоит из нескольких обязательных шагов. Простой пример для PR:\n\nПри открытии каждого Pull Request, Git-сервер отправляет уведомление CI-серверу;\nCI-сервер клонирует репозиторий, проверяет исходную ветку (например bugfix/wrong-sorting), и сливает код с кодом master-ветке;\nТогда запускается билд-скрипт (сценарий сборки). Например ./gradlew build;\nЕсли эта команда возвращает код ответа “0”, то билд успешно выполнен. (Другой ответ означает ошибку);\nCI-сервер направляет уведомление об успешном билде на Git-сервере;\nЕсли билд был успешен, то Pull Request разрешается слить с существующим кодом. (Если не успешен, то, соответственно, не разрешается).\nОшибка в любом из шагов приводит к полному падению всей сборки. Ну и, само собой разумеется, шаги расположены в таком порядке, чтобы сужать воронку потенциальных проблем. Если Quality Gate предыдущего этапа не пройдет, то на проверку следующего уже можно не тратить ресурсы.\n\nПример Quality Gates, которые встроены в pipeline отсюда:\n\nСборка сервиса:\nПроверка наличия конфигурации корректного формата;\nПроверка стандартов оформления кода;\nПроверка на необходимое покрытие Unit-тестами;\nГенерации и публикации контрактов (контроль обратной совместимости).\nЗапуск Beta-тестов;\nОбязательный code-review;\nСканирование на уязвимости.\nПример сферического пайплайна в вакууме отсюда:\n\nCode scanning: код проверяется на соответствие общему гайдлайну (linters), уязвимости (code security) и качество (code quality);\nUnit tests;\nBuild: этап для сборки artifacts/packages/images и т.д. Здесь уже можно задуматься о том, каким будет стратегия версионирования всего приложения. Во времена контейнеризации, в первую очередь интересуют образы для контейнеров и способы их версионирования;\nScan package: пакет/образ собрали. Теперь нужно просканировать его на уязвимости. Современные registry уже содержат инструментарий для этого;\nDeploy: стадия для развертывания приложения в различных окружениях;\nIntegration testing: приложение задеплоили. Оно где-то живет в отдельном контуре. Наступает этап интеграционного тестирования. Тестирование может быть как ручным, так и автоматизированным;\nPerformance testing (load/stress testing): данный вид тестирования имеет смысл проводить на stage/pre-production окружениях. С тем условием, что ресурсные мощности на нем такие же, как в production;\nCode Review / Approved: одним из важнейших этапов являются Merge Request. Именно в них могут производиться отдельные действия в pipeline перед слиянием, а также назначаться группы лиц, требующих одобрения перед слиянием.\n\n\n53. Опишите пример процесса CI (и/или CD), который начинается с момента, когда разработчик запушил изменения/PR в Git?\n\n54. Расскажите о разновидностях тестов, которые мы можем использовать в CI пайплайне.\n\n55. Какие инструменты CI вы использовали? Есть ли опыт работы с Jenkinsfile?\n\n56. Какие виды тестов вы знаете и зачем они нужны?\n\n72. Как автоматическое тестирование интегрируется в CI?\n\n73. Как настроить Job или Pipeline на знакомом вам CI-инструменте?\n\n74. Какие инструменты для генерации репорта после выполнения автоматических тестов вы знаете?\n\n75. Какую информацию должен содержать отчет о выполнении автоматических тестов?","date":"2022-07-27T00:00:00.000Z","path":"/ci-cd/","icon":"fas fa-robot","image":"null","order":2,"category":{"title":"testops","path":"/category/testops/"},"tags":[{"title":"Автоматизация тестирования","path":"/tag/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F/"},{"title":"CI","path":"/tag/CI/"},{"title":"CD","path":"/tag/CD/"}],"headings":[{"value":"Принципы CI/CD","anchor":"#принципы-cicd"},{"value":"Этапы CI/CD","anchor":"#этапы-cicd"},{"value":"Общий принцип CI/CD-разработки","anchor":"#общий-принцип-cicd-разработки"},{"value":"Недостатки CI/CD","anchor":"#недостатки-cicd"},{"value":"Инструменты для CI/CD","anchor":"#инструменты-для-cicd"},{"value":"Вопросы","anchor":"#вопросы"}]}},{"node":{"id":"e32cda98ac188fcccf94b3fd1cf66fcf","title":"Docker","content":"\nDocker - это средство упаковки (в контейнеры), доставки и запуска (запуск осуществляется одним и тем же образом, единый интерфейс) приложения.\nДокер - это история про виртуализацию, но не ту какую вам предоставляют виртуальные машины, которые разворачивают полноценную ОС внутри вашей. Главная задача Докера запустить приложение. \n\n## Базовые понятия\n\nDocker image - это сборка, говтовое к запуску приложение, но еще не запущеное.\n\nDocker container -  работающее приложение, созданное на базе имеджа.\n\nНа основе одного образа можно создать много одинаковых контейнеров.\nНапример, нужно 10 реплик одного сервиса.\n\nДля контейнера образ является read only системой, он не может его изменить.\n\nImage - слоеный пирог, напрмиер image Ubuntu и возьмем его за базу и поставим туда Nginx и поставим туда mongo и поставим питон.\n\nРеестр имеджей - он находится локально там хранятся те images которые создали именно вы.  \nТакже есть docker hub - там реестр всех имеджей, которые поддерживаются создателями докера но так же и те которые создавали другие люди.\n\n## Посмотреть images\n\n```\ndocker images\n```\n\n## Посмотреть запущенные контейнеры\n\n```\ndocker ps\n```\n\n-a - посмотреть в том числ остановленные контейнеры\n-a -q - отобразить только id контейнера\n\n## Создаем свой докер образ\n\n```\ndocker build -t hello-world .\n```\n\ndocker build - команда для создания образа\n-t - тег, название образа\n. - путь к текущей директории (где находится приложение)\n\nТакже нужно указать как именно нужно упаковать приложение, для этого создается Dockerfile.\n\nВ Dockerfile нужно описать шаги для упаковки нашего приложения.\n\n```docker\nFROM python:3.6 \n\nRUN mkdir -p /usr/src/app/\nWORKDIR /usr/src/app/\n\nCOPY . /usr/src/app/\n\nCMD [\"python\", \"app.py\"]\n```\n\n- FROM - базовый образ, через :(двоеточие) указывается тег\n- RUN - указывает что нужно выполнить указанную команду\n- WORKDIR - начальный каталог в который нужно перейти\n- COPY - копирует содержимое из источника в целевую папкув контейнере\n- CMD - указывает какие команды нужно выполнить когда мы запустим контейнер, запускает команды через shell \n- ENTRYPOINT - аналог CMD, но команды выполняются без shell оболочки\n\n## Запуск контейнера\n\n- запуск контейнера  \ndocker run <имя образа>\n```\ndocker run hello-world\n```\n\nКонтейнер работает до тех пор пока работает приложение.\n\n- задаем имя контейнера при запуске  \ndocker run **--name** <имя контейнера> <имя образа>\n```\ndocker run --name hello hello-world\n```\n\n- запуск контейнера в фоне, чтобы можно было работать с консолью  \ndocker run --name <имя контейнера> **-d** <имя образа>\n```\ndocker run --name hello -d hello-world\n```\n\n- запуск контейнера с автоудалением после остановки  \ndocker run --name <имя контейнера> -d **--rm** <имя образа>\n```\ndocker run --name hello -d --rm hello-world\n```\n\n## Удалить контейнер\n\nНапример те которые уже отработали\n\n- удалить один контейнер\ndocker rm <id контейнера>\ndocker rm <имя контейнера>\n```\ndocker rm 1e0c7cd00041\n```\n\n- удалить все контейнеры\ndocker rm $(docker ps -qa) \n\n## Остановить контейнер\n\n- docker stop <id контейнера>\n- docker stop <имя контейнера>\n\n## Проброска портов\n\nКонтейнер собирается в полностью изолированном окружении и если явно не пробросить порты то приложение будет не видно.\n\nЧтобы пробросить порт нужно в Dockerfile указать EXPOSE 8080 тем самым мы указываем что мы можем этот порт пробросить.\n\nЧтобы выполнить проброску нужно при запуске контейнера указать флаг -p и через двоеточие 2 порта (1- порт нашей машины, 2 - порт в контейнере)\n\ndocker run --name <имя контейнера> --rm -p 8080:80880 <имя образа>\n```\ndocker run --name hello --rm -p 8080:80880 hello-world\n```\n\n## Переменные окружения\nМожно указать в Dockerfile\n\nENV <название переменной> <значение>\n\nно иногда переменные нужно менять поэтому можно указывать переменные при запуске контейнера\n\ndocker run --name <имя контейнера> --rm -p 8080:80880 -e <имя переменной>=<значение> <имя образа>\n```\ndocker run --name hello --rm -p 8080:80880 -e TZ=Europe/Moscow hello-world\n```\n\n## Работа с внешними данными\n\n1. монтируем папку\nделается это при запуске контейнера через параметр -v\n\ndocker run --name <имя контейнера> --rm -p 8080:80880 -v <папка на хостовой машине(абсолютный путь)>:<папка в контейнере(абсолютный путь)> <имя образа>\n```\ndocker run --name hello --rm -p 8080:80880 -v ...:... hello-world\n```\n\n2. docker volume\n\nпосмотреть какие volume доступны\n\n```\ndocker volume ls\n```\n\nчтобы создать volume\n\n```\ndocker volume create <имя>\n```\n\nтеперь при запуске можно указать \n\ndocker run --name <имя контейнера> --rm -v <имя volume>:<папка в контейнере(абсолютный путь)> <имя образа>\n```\ndocker run --name hello --rm -p 8080:80880 -v ...:... hello-world\n```\n\n## Удалить image\n\ndocker rmi <имя image>\n\n## Получить список images id \n\ndocker images -q\n\n## Удалить все images\n\ndocker rmi $(docker images -q)\n\n## Многосервисная архитектура \n\nДля каждого сервиса имеется свой Dockerfile. \nЕсли через docker run выполнять настройке переменных когда есть много сервисов это не совсем удобно.\n\nДля этого используется docker-compose - надстройка над докером.\n\nДля его использования нужно создать docker-compose.yaml\n\n\nуказываем версию, volumes и описываем настройки каждого сервиса\n\n**Настройки сервиса:**\n\nbuild: указываем откуда взять Dockerfile либо image: mongo:latest если нужно взять готовый образ\n\nvolumes: \n  - <имя volume>:<абсолютный путь к папке в контейнере>\n\nports: - проброска портов\n  - 8080:8080 \n\nrestart: always - если вдруг машина перезагрузится то докер сам перезапустит контейнеры\n\nenvironment: - перечисляем переменные окружения\n- TZ=Europe/Moscow\n\n## Создаем ssh ключ\n\nпереходим из домашнего каталога в .ssh и запускаем ssh-keygen, затем выводим на экран публичный ключ\n\n```\ncd .ssh\nssh-keygen -t rsa\n# задаем имя, например vscale\ncat vscale.pub | pbcopy\n```\n\nсоздаем в папке .ssh файл config\n```\nvim config\n```\n\nУказываем в config настройки\n\nhost <имя хоста пожеланию>\n  hostname <шз адрес сервера>\n  user root\n  IdentityFile ~/.ssh/vscale\n\nСозряняем и выполняем команду \nssh vs\n\n## Устанавливаем docker на сервере\n\n```\nsudo apt update\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\nsudo add-app-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\"\nsudo apt install docker-ce\n```\n\n## Устанавливаем docker-compose на сервере\n\n```\nsudo curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-`uname -s` -`uname -m` -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\ndocker-compose --version\n```\n\n## Запуск docker-compose\ndocker-compose up -d\n\n-d - чтобы контейнеры в фоне работали\n\n## Остановить docker-compose\ndocker-compose down -d\n\n## Работа с docker hub\n\nСоздать свой репозиторий можно с сайта hub.docker.com нажав Create Repository  \nлибо просто запушив свои первый image\n\nнужно в имя образа вставить идентификатор пользователя и через / имя репозитория\n\n```\ndocker build -t artemproject/statisticmanager .\ndocker login\ndocker push artemproject/statisticmanager\n```\n\n## Запуск postgres в docker\nЧтобы запустить postgres в docker нужно:\n\n1. Сделать pull image\n\n```docker\ndocker pull postgress\n```\n\n2. Запустить инстанс докера\n\n```docker\ndocker run --name some-postgres -e POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 -d postgres\n```\n\n--name - имя контейнера на локальной машине\nPOSTGRES_PASSWORD= - здесь указывается пароль\n-d (detach) необходимо указывать для того чтобы терминал оставвался терминалом локального компьютера, а не терминалом БД\npostgres - название контейнера который мы будем запускать\n-p 5432:5432 - проброс портов, порт внутри контейнера будет соответсвовать порту нашего компьютера\n\n3. Проверяем запущенные контейнеры\n\n```docker\ndocker ps -a\n```\n\nДля работы с БД нужно подключить Postgress JDBC - `'org.postgresql:postgresql:42.3.6'`\nи часть фреймворка Spring для работы с БД - `'org.springframework:spring-jdbc:5.3.20'`\n\nсистема виртуализации для запуска приложения в ихолированной среде.\n\nSELECT departamens.name FROM departamens LEFT JOIN users ON users.departament_id = departamens.id WHERE users.departament_id IS NULL;\n\n\n\n\n","date":"2022-07-28T00:00:00.000Z","path":"/docker/","icon":"fas fa-robot","image":"null","order":2,"category":{"title":"testops","path":"/category/testops/"},"tags":[{"title":"Автоматизация тестирования","path":"/tag/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F/"}],"headings":[{"value":"Базовые понятия","anchor":"#базовые-понятия"},{"value":"Посмотреть images","anchor":"#посмотреть-images"},{"value":"Посмотреть запущенные контейнеры","anchor":"#посмотреть-запущенные-контейнеры"},{"value":"Создаем свой докер образ","anchor":"#создаем-свой-докер-образ"},{"value":"Запуск контейнера","anchor":"#запуск-контейнера"},{"value":"Удалить контейнер","anchor":"#удалить-контейнер"},{"value":"Остановить контейнер","anchor":"#остановить-контейнер"},{"value":"Проброска портов","anchor":"#проброска-портов"},{"value":"Переменные окружения","anchor":"#переменные-окружения"},{"value":"Работа с внешними данными","anchor":"#работа-с-внешними-данными"},{"value":"Удалить image","anchor":"#удалить-image"},{"value":"Получить список images id","anchor":"#получить-список-images-id"},{"value":"Удалить все images","anchor":"#удалить-все-images"},{"value":"Многосервисная архитектура","anchor":"#многосервисная-архитектура"},{"value":"Создаем ssh ключ","anchor":"#создаем-ssh-ключ"},{"value":"Устанавливаем docker на сервере","anchor":"#устанавливаем-docker-на-сервере"},{"value":"Устанавливаем docker-compose на сервере","anchor":"#устанавливаем-docker-compose-на-сервере"},{"value":"Запуск docker-compose","anchor":"#запуск-docker-compose"},{"value":"Остановить docker-compose","anchor":"#остановить-docker-compose"},{"value":"Работа с docker hub","anchor":"#работа-с-docker-hub"},{"value":"Запуск postgres в docker","anchor":"#запуск-postgres-в-docker"}]}},{"node":{"id":"3654d47de6821c30e1c8992c6fcf5550","title":"Подходы к автоматизации тестирования","content":"\n## Виды подходов\nВ автоматизированном тестировании выделяют следующие подходы:\n\n1. TDD (англ. Test Driven Development);\n2. BDD (англ. Behaviour Driven Development);\n3. KDT (англ. Keyword Driven Testing);\n4. DDT (англ. Data-driven testing).\n\n## Data-Driven Testing\nЭто тестирование, управляемое данными. При таком подходе тестовые данные хранятся отдельно от тест-кейсов, допустим, в файле либо в базе данных. Такое разделение логически упрощает тесты.\n\nData-Driven Testing используется в тех проектах, где нужно выполнить тестирование отдельных приложений в нескольких средах с большими наборами данных и стабильными test cases.\n\nОбычно при DDT выполняются следующие операции:\n- извлечение части тестовых данных из хранилища;\n- ввод данных в форму приложения;\n- проверка результатов;\n- продолжение тестирования со следующим набором входных данных.\n\nЧтобы проверка приложения была успешна, потребуются разные комбинации данных. \n\n## Keyword Driven Testing\nРечь идёт о тестах, управляемых ключевыми словами. Данный подход предполагает использование ключевых слов, описывающих набор действий, нужных для выполнения конкретного шага тестового сценария. \n\nПри таком подходе в первую очередь определяется набор ключевых слов, а только после этого ассоциируется функция либо действие, связанное с данным ключевым словом. Например, каждые шаги теста, такие как щелчок мышью, нажатие клавиши, открытие либо закрытие браузера описываются определёнными ключевыми словами («открыть» — openbrowser, «нажать» — click и т. п.).\n\nПри KDT-подходе вы можете создавать простые функциональные тесты на самых ранних этапах разработки и тестировать приложение по частям. \n\nЭтапы разработки KDT-тестов:\n\n1. Определяем ключевые слова.\n2. Реализуем ключевые слова как исполняемые файлы.\n3. Создаём тест-кейсы.\n4. Создаём скрипты.\n5. Выполняем автоматизированные сценарии.\n\nПлюсы подхода:\n\n1. функциональные тестировщики могут планировать автоматизацию тестирования до того, как приложение будет готово;\n2. тесты можно разработать без знаний программирования;\n3. подход не зависит от выбранного языка программирования. \n\n## Test Driven Development\nПодход разработки через тестирование (TDD) предполагает организацию автоматического тестирования посредством написания модульных, функциональных и интеграционных тестов, определяющих требования к коду перед написанием кода.\nТо есть в первую очередь пишется тест, проверяющий корректность работы ещё ненаписанного кода. Тест, само собой, не проходит. Далее программист пишет код, где выполняются действия, необходимые для прохождения теста. Когда тест будет успешно пройден, возможна доработка имеющегося кода.\n\nРазработка через тестирование — это больше, чем просто проверка корректности, так как она оказывает влияние и на дизайн программы. Если вы изначально сфокусированы на тестах, вам проще представить, какая именно функциональность нужна пользователю. В результате разработчик продумает детали интерфейса до его реализации. Это, в свою очередь, сократит время на разработку и отладку.\n\nКроме того, разработка через TDD сосредотачивается на тестировании отдельно взятых модулей, при этом используются заглушки (mock-объекты) для представления внешнего мира.\n\n## Behavior Driven Development\nПодход BDD — это разработка, основанная на поведении. По сути, BDD является разновидностью (расширением) TDD с той лишь разницей, что BDD-подход ориентирован на поведение сущности, которую вы тестируете (в TDD основной фокус идёт непосредственно на сам код). Суть BDD заключается в описании системы архитектуры приложения в терминах, понятных неспециалисту. Это даёт возможность ускорить процесс получения обратной связи, убрав традиционные барьеры. То есть описание пользовательских сценариев происходит на естественном языке — грубо говоря, на языке бизнеса.\n\n#### Источник информации:\n1. [Подходы к автоматизации тестирования веб-приложений](https://otus.ru/nest/post/1083/)","date":"2022-08-04T00:00:00.000Z","path":"/podhody-k-avtomatizaczii-testirovaniya/","icon":"fas fa-robot","image":"null","order":3,"category":{"title":"interview","path":"/category/interview/"},"tags":[{"title":"Автоматизация тестирования","path":"/tag/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F/"},{"title":"подходы к автоматизации","path":"/tag/%D0%BF%D0%BE%D0%B4%D1%85%D0%BE%D0%B4%D1%8B%20%D0%BA%20%D0%B0%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8/"}],"headings":[{"value":"Виды подходов","anchor":"#виды-подходов"},{"value":"Data-Driven Testing","anchor":"#data-driven-testing"},{"value":"Keyword Driven Testing","anchor":"#keyword-driven-testing"},{"value":"Test Driven Development","anchor":"#test-driven-development"},{"value":"Behavior Driven Development","anchor":"#behavior-driven-development"}]}},{"node":{"id":"fdabea050bd600941e7f616a86f828f0","title":"Kubernetes","content":"\n## Kubernetes\nKubernetes - открытая платформа созданная для автомтаического деплоя, масштабирования и оперирования контейнерами приложений.\n\nПортативная расширяемая платформа с открытым исходным кодом для управления контейнеризованными рабочими нагрузками и сервисами которая облегчает как декларативную настройку так и автоматизацию.\n\nKubernetes состоит из нод. Как правило рекомендуют использовать не менее 3х нод для Kubernetes. \nMaster Node и 2 Work Nodes. \n\n**Master Node** - отвечает за поддержание желаемого состояния для вашего кластера.\nС Master Node взаимодействует kubectl - интерфейс командной строки, который позволяет через командную строку управлять Kubernetes кластером.\n\nС другой стороны у нас есть пользователь, который через интернет обращается к нашему приложению через Work Node и через kube-proxy ходит непосредственно на pod'ы.Основные фундаментальные концепции Kubernetes -  это pod и node, а также kublet, kube-proxy, etcd.\n\n**Nodes(узлы)** - это виртуальные либо физические машины в Kubernetes кластере на которых будут запускаться контейнеры.\nНода содержит kublet, Docker, kube-proxy. Также нода может содержать 1 или несколько под.\n\n**Pod** - минимальный юнит в Kubernetes с которым можно взаимодействовать, абстрактный объект Kubernetes представляющий группу из одного или нескольких контейнеров приложения (например Docker).\n\nПоды можно создавать, деплоить и удалять. Одна пода - один процесс в кластере. \nПод содержит: Docker container, storage resources, уникальный IP. \n\n**Cluster** - совокупность мастер-сервисов и нод.\n\n**Namespace** - это способ разделения ресурсов кластера между несколькими пользователями.\nНапример, namespace команд, проектов и тд.\n\nЧтобы зайти в кластер и начать запускать команды нужно установить kubectl.\n\nkubectl - это инструмент командной строки kubernetes, который позволяет запускать команды для кластеров Kubernetes. Вы можете использовать kubectl для развертывания приложений проверки и управлени ресурсов кластера а также просмотра логов\n\n### Жизненный цикл Pod\n\n- Pending - ожидание, под ждет ресурсов. Под был принят кластером но один или несколько контейнеров еще не были запущены и нужно подождать.\n- Running - запуск, созданы контейнеры необходимые для пода и запуска непосредственно на этой ноде. Под привязан к узлу и все контейнеры созданы.\n- ContainerCreating - собираются контейнеры.\n- Succeeded/Completed - успешный запуск, все контейнеры созданы, работают, нода запущена.\n- CreateContainerConfigError - ошибка конфигурации.\n- Failed - неуспешный запуск, запуск зафейлился приходит response != 1\n- CrashLoopBackOff - под уходит в бесконечный цикл. Под был запущен крашнулся перезапустился и заново крашнулся (установлено значение restartPolicy: Always) нужно изучить логи.\n- Terminating -  трафик не идет на под, под тушится после его удаления\n\nЧтобы работало автодоплнение нужно выполнить команду:\n\n```\nsource <(kubectl completion bash)\n```\n\nДалее нужно получить доступ к кластеру:\n\n- Получить список всех неймспейсов\n```\nkubectl get namespaces\n```\n\n- получить список всех подов во всех неймспейсах\n```\nkubectl get pods --all-namespaces\n```\n\n- получить список всех подов во всех неймспейсах там где есть название ssr с подробным выводом логов\n```\nkubectl get pods --all-namespaces -o wide |grep ssr\n```\n\n- получить список подов в определенном неймспейсе\n```\nkubectl get pods -n core-team\n```\n\n```\nkubectl get pods -n core-team|grep besida-madmax\n```\n\nПосле того как вышел список подов мы можем увидеть статусы в которых они находятся:\n\n- Обзор запущенного пода\n```\nkubectl -n core-team describe pod besida-trunk-ua-685d5d4f-hpdw2\n```\n\n- Вывести логи пода \n```\nkubectl -n core-team logs besida-trunk-ua-685d5d4f-hpdw2\n```\n\nотображает логи на лету\n```\nkubectl -n core-team logs -f besida-trunk-ua-685d5d4f-hpdw2\n```\n\n### Controllers\n\nУправляется Controller Manager'ом. \n\nВиды контроллеров:\n- ReplicaSets - проверяет что необходимое количество pod запущено все время. Если pods стало меньше (например одна изпод закрешилась), то replicaSet создаст новую. ReplicaSets существует не самостоятельно а в рамках Deployment.\n\n- Deployments - предоставляет декларативное описание для апдейта ReplicaSet и Pod. В ранних версиях Kubernetes вместо ReplicaSet и Deployment использовался Replication Controller. Но это нарушало принцип single responsibilities и в дальнейшем он был разделен и облегчилась задача rollback'a - если во время деплоймента что то пошло не так то в текущих условиях легко откатиться назад и востановить работоспособность приложения.  \n\n- DeamonSets - проверяет что на каждой ноде запущен экземпляр конкретной поды. Если ноды добавляются в кластер или удаляются из кластера то DeamonSet добавить или удалить поды на этой ноде. Удаление DeamonSet означает удаление всех под из кластера.\n\n- Jobs - это процесс верхнего уровня для пода. Используется когда нужно запустить pod для выполнения какой то задачи один раз или по расписанию. Типичный пример - cron job.\n\n- Services - позволяет сетевое взаимодействие между деплойментами. Необходимы, когда нужно, чтобы поды из разных деплойментов взаимодействовали между собой. \n\nНапример: FrontEnd Pod взаимодействует с BackEnd Pods через Backend Service.\n\n### Виды сервисов:\nInternal - ip-адрес доступен только внутри кластера. \n\nExternal - эндпоинт доступен по ip адресу ноды(такой сервис называют NodePod). \n\nLoad Balancer - открывает приложение в интернет через лоад балансер (обычно используется когда кубернетис кластер развернут в облаке (GCP, AWS, Azure).\n\n\n### Labels\n\nПара ключ/значение, может быть присоединена к таким объектам как поды, сервисы и доплойменты. Используются пользователями Кубернетис для идентификации аттрибутов для объектов. Уникальны в пределах объекта. \n\nПример: \"environment\": \"dev\", \"environment\": \"qa\", \"environment\": \"prod\"\n\nLabels как правило используются не одни а с selectors.\n\n### Selectors\n\n- equality-based: '=' и '!='\n- Set-based: 'IN', 'NOTIN' и 'EXISTS'\n\nLabels и Selectors обычно используются в kubectl командах для получения списков объектов и их фильтрации. НапримерЖ получение списка под на QA env.\n\n### Namespaces\n\nКонцепция неймспейсов позволяет реализовать множество виртуальных кластеров внутри одного физического кластера. Это полезно, когда есть необходимость разделять ресурсы физического кластера между командами и контролировать доступ к ресурсам.\n\n### Kublet\n\n- Запущен на каждой work-ноде\n- Коммуницирует с API сервером, который запущен на Master Node\n- Запускает контейнеры для под через docker engine\n- Подключает и запускает диски и сикреты для под\n- Запускает хелсчеки для проверки статусов под/нод и сообщает статус API серверу\n\n### Kube-proxy\n\n- Запущен на каждой work-ноде\n- Рефлицирует сетевой трафик для сервисов (NodePort и LoadBalancer)\nконфигурирует правила сети на узлах. При помощи них разрешаются сетевые подключения к вашими подам изнутри и снаружи кластера.\n\n\n### Режимы Kube-proxy\n\n- User space mode (наиболее широко используемый)\n- Iptables mode\n- Ipvs mode (alpha version)\n\n### etcd\nРаспределённое и высоконадёжное хранилище данных в формате \"ключ-значение\", которое используется как основное хранилище всех данных кластера в Kubernetes.\n\n### kube-scheduler\nКомпонент плоскости управления, который отслеживает созданные поды без привязанного узла и выбирает узел, на котором они должны работать.\n\n\n## Команды Kubernetes\n\n- получить список подов\n```\nkubectl get pods\n```\n\n- получить список сервисов\n```\nkubectl get services\n```\n\n- получить список деплойментов\n```\nkubectl get deployments\n```\n\n- поднимаем selenium-hub\n```\nkubectl create -f selenium-hub-deployment.yaml\n```\n\n- поднимаем selenium-hub-svc\n```\nkubectl create -f selenium-hub-svc.yaml\n```\n\n- поднимаем selenium-node\n```\nkubectl create -f selenium-node-chrome-deployment.yaml\n```\n\n\n\n\n## CI/CD microservices\n\nCI - Continious Integration это когда разработчики интегрируют свои код в общий репозиторий на постоянной основе и постоянно проходят некий quality gate который показывает что их код синтегрировался корректно. \n\nCD - Continious Delivery это когда артефакт который мы собрали в рамках Continious Integration и начинаем поставлять его на разные окружения.\nContinious De[loyment это когда мы в процессе Continious Delivery не ждем ручного апрува а автоматом через энвайронменты проводим и выкатываем на продакшен.\n\nКак этого достичь:\n1. Докеризация микросервисов\nнужно получить артефакт который будет неизменным - нужно быть уверенным что тот артефакт который мы собрали в таком же виде дойдет до продакшена\n2. Мы можем присваивать артефакту теги и тем самым продвигать его на следущую стадию\n3. Мы не завязываемся на технический стек\n4. Это прощает деплоймент, управление окружением, конфигурацию и т.д.\n5. Эфективное использование ресурсов\n\nУ нас есть контейнер - запущенный процесс который представляет наш микросервис и image - immutable артефакт который мы собрали в рамках  CI и выложили его в registry - реестр images, где хранятся наши артефакты.\n\n## Версионирование\n\nСемантическое версионирование - \nглавная версия отвечает за то какие знаковые изменения были сделаны в микросервисе(то что мы не поломали API), если мы не имеем обратной совместимости то увеличиваем эту версию либо по большим релизом и с каждым релизом увеличиваем;\nминорная версия - либо начинаем каждый раз с нуля в рамках каждого нового большошо релиза либо если девелопим интерациями то используют номер интерации, тогда можно быстро востановить когда эта версия была выпущена.\nпатч версия - для хот фиксов \nкомит хештег как суффикс и дата как дополнительный суффикс\n\n## CI pipeline\n\nРазработчик делает комит в гит репозиторий на CI делается: build code, run unit tests, build image, push image(пушится в реестр контейнеров). На выходе мы получаем кодовые артифакты, результаты тестов, image контейнер.\n\nQuality Gates:\n- unit tests\n- integration tests\n- static code analysis\n- api tests\n- contract tests\n- security checks\n\nЧтобы поставить полностью всю систему нужно знать версии всех микросервисов.\n\nЗдесь нужно учитывать совместимость - это когда мы взяли набор микросервисов подняли провели тесты и после этого мы говорим что этот набор сервисов совместим \n\nПоэтому нужно сохранять нобор версий этих сервисов как отдельный артефакт \nЭтот артефакт можно положить в систему контроля версий(например гит)\nДальше в Continious Delivery будет участвовать этот набор. и дальше можно промоутить этот артефакт между разными окружениями. Если мы добавим зависимость на какую то версию postgress или elastic то мы получим полную совместимсоть\n\nЭто делается с помощью property файла и прописываем версии.\nМожно использовать helm.\n\n**Пример:**\n\nУ нас есть 3 сервиса с соответсвущими версиями и мы их собрали в compatible set. \n\nИ тут появляется доработка в одном из сервисов и появляется его новая версия и это новый кандидат мы хотим его продвинуть. \n\nМы собираем новый set с этим кандидатом и пытаемся его запустить и билд падает(возможно оказалась проблема в несовместимости например с ui частью).\n\nИ появилась необходимость сделать исправление в другом микросервисе, разработчики делают исправление, получают новую версию и хотят ее задеплоить. И тут вступает фактор, что нужно подхватывать всех новых кандидатов, потому что если бы подхватили только последний кандидат, он могбы упасть так как ожидает исправлений, которые появились в первом сервисе.\n\nЕсли билд проходит успешно, то мы делаем совместимый между собой set и сохраняем его в сисетму контроля версий.\n\nЕсли билд падает, то артифакт невидим и нет возможность такой билд куда-то задеплоить просто так, не пройдя тест на совместимость. \n\nПосле того как артефакт появился в системе контроля версий, то либо jenkins джоба это проверяет, либо оператор в Kubernetes переодически мониторит что появляется и говорит что надо это деплоить - вручную или по расписанию. \n\nFlux CD мониторит появление новых images в гите и говорит что можно их задеплоить.\n\n## Выполняем деплой на окружение\n\nДля этого мы создаем Jenkins джобу или github actions которая показывает нам список окружений который нам доступен: dev, qa, stage, prod либо оставляем создаем новое окружение. Также показываются для выбора не отдельные микросервисы а показыватся сеты. Еще нужно указать TTL(Time To Live) окружение будет автоматически очищаться по истечению времени. \n\nНо если будет много окружений - это займет все ресурс и для решения этой проблемы нужен Kubernetes.\n\nКак ускорить создание окружения в Kubernetes:\n- каждое окружение уходит в отдельый namespace \n- конфигурируем минимальные лимиты и scale фактор \n- выносим основные внешние ресурсы (DB, Elastcsearch, Redis, Kafka)\n- используем готовые images с данными\n- сконфигурируем все тулы \n- асинхронное удаление окружение\n- задаем TTL\n\n\nzhuk.__\n\n","date":"2022-07-27T00:00:00.000Z","path":"/kubernetes/","icon":"fas fa-robot","image":"null","order":3,"category":{"title":"testops","path":"/category/testops/"},"tags":[{"title":"Автоматизация тестирования","path":"/tag/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F/"}],"headings":[{"value":"Kubernetes","anchor":"#kubernetes"},{"value":"Команды Kubernetes","anchor":"#команды-kubernetes"},{"value":"CI/CD microservices","anchor":"#cicd-microservices"},{"value":"Версионирование","anchor":"#версионирование"},{"value":"CI pipeline","anchor":"#ci-pipeline"},{"value":"Выполняем деплой на окружение","anchor":"#выполняем-деплой-на-окружение"}]}},{"node":{"id":"88d572eb7ef5e159071648216897aa21","title":"Фреймворки автоматизации тестирования","content":"\nВ каждой команде разработки и поставки ПО группа QA отвечает за разработку, внедрение и выполнение тестов. Для каждого типа тестирования должен быть определён тестовый сценарий, принципы, правила и инструменты для проведения. Фреймворк тестирования — это набор этих руководств, инструментов и практик, который помогает инженерам-тестировщикам эффективно выполнять тестовые сценарии.\n\nСуществуют разные фреймворки для разных целей тестирования. Вот некоторые из самых популярных типов фреймворков для автоматизированного тестирования:\n\n## Модульный\nПриложение разделено на отдельные модули, и каждый модуль тестируется в изолированном состоянии;\n\n## Линейный\nСоставление и исполнение тестовых скриптов. Тестировщики пишут тестовые сценарии последовательно, выполняя их затем для каждого отдельного тест-кейса;\n\n## Библиотечная архитектура\nСоздан на основе модульного фреймворка тестирования, с той лишь разницей, что содержит функции для многократного использования;\n\n## Управляемое данными тестирование\nТестовые скрипты выполняются и верифицируются на основе данных, которые хранятся в центральном хранилище данных или базе данных (SQL, ODBC-ресурсы, csv или xls файлы);\n\n## Тестирование по ключевым словам\nВ данном фреймворке не обязательно иметь навыки программирования, поскольку ключевые слова, используемые при создании тестов, отделены от технического кода. \nТестировщику достаточно иметь представление о всём наборе действий, реализованных во фреймворке;\n\n## Гибридный\nКомбинация из различных фреймворков.\n\nГлавная цель всех команд разработчиков программного обеспечения — обеспечить быструю поставку качественного и надежного программного продукта. Чтобы обеспечить быстрый и эффективный процесс поставки, необходимо непрерывное тестирование. Автоматизация — ключ к тому, чтобы разрабатываемое ПО могло быстро пройти через все стадии конвейера разработки и предоставить клиентам свои функции. Однако, это не означает, что команды должны вкладывать всё свое время и ресурсы в автоматизацию тестирования. Команды должны понимать, что можно и нужно автоматизировать, а что не стóит. Правильный выбор охвата тестов на ранних этапах разработки имеет большое значение.","date":"2022-08-04T00:00:00.000Z","path":"/frejmvorki-avtomatizaczii-testirovaniya/","icon":"fas fa-robot","image":"null","order":4,"category":{"title":"interview","path":"/category/interview/"},"tags":[{"title":"Автоматизация тестирования","path":"/tag/%D0%90%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%20%D1%82%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F/"},{"title":"фреймворки автоматизации","path":"/tag/%D1%84%D1%80%D0%B5%D0%B9%D0%BC%D0%B2%D0%BE%D1%80%D0%BA%D0%B8%20%D0%B0%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8/"}],"headings":[{"value":"Модульный","anchor":"#модульный"},{"value":"Линейный","anchor":"#линейный"},{"value":"Библиотечная архитектура","anchor":"#библиотечная-архитектура"},{"value":"Управляемое данными тестирование","anchor":"#управляемое-данными-тестирование"},{"value":"Тестирование по ключевым словам","anchor":"#тестирование-по-ключевым-словам"},{"value":"Гибридный","anchor":"#гибридный"}]}}]}},"relatedTag":null},"context":{}}